{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "param_alpha = 0.01\n",
    "param_corpus = 'corpus/andersen.txt'\n",
    "param_model = 'arthur_store.h5' #output\n",
    "param_verbose = False\n",
    "param_balancing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working datasets\n",
    "prominence = {}\n",
    "prominence[1] = pd.DataFrame(columns=['word1', 'cooc'])\n",
    "prominence[2] = pd.DataFrame(columns=['word1', 'word2', 'cooc'])\n",
    "prominence[3] = pd.DataFrame(columns=['word1', 'word2', 'word3', 'cooc'])\n",
    "prominence[4] = pd.DataFrame(columns=['word1', 'word2', 'word3', 'word4', 'cooc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ngram1(pos, sentence):\n",
    "  n = 1\n",
    "  word = {}\n",
    "  global prominence\n",
    "  \n",
    "  if pos > len(sentence) - n:\n",
    "    return\n",
    "  for i in range(1, n+1):\n",
    "    word[i] = sentence[pos+i-1]\n",
    "    word[i] = word[i].upper()\n",
    "  \n",
    "  # read the unigram\n",
    "  selector = (prominence[n].word1==word[1])\n",
    "  records = prominence[n].loc[selector]\n",
    "  # update the unigram\n",
    "  if len(records.index) == 0:\n",
    "    # insert\n",
    "    c = 1 * param_alpha\n",
    "    signature = {'word1': [word[1]],'cooc': [c]}\n",
    "    prominence[n] = prominence[n].append(\n",
    "        pd.DataFrame(signature),ignore_index=True, sort=False)\n",
    "  elif len(records.index) == 1:\n",
    "    # update\n",
    "    oldc = records['cooc'].iloc[0]\n",
    "    c = oldc * (1 - param_alpha) + 1 * param_alpha\n",
    "    prominence[n].loc[selector,'cooc'] = c\n",
    "  else:\n",
    "    print(\"Invalid code path\")\n",
    "\n",
    "  # update weights for other unigrams\n",
    "  selector_neg = (prominence[n].word1!=word[1])\n",
    "  if param_balancing:\n",
    "    if not selector_neg.empty:\n",
    "      prominence[n].loc[selector_neg,'cooc'] *= (1 - param_alpha)\n",
    "\n",
    "  # finish\n",
    "  if param_verbose:\n",
    "    print(\"Updated ngram: {w1}\".format(w1=word[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ngram2(pos, sentence):\n",
    "  n = 2\n",
    "  word = {}\n",
    "  global prominence\n",
    "  \n",
    "  if pos > len(sentence) - n:\n",
    "    return\n",
    "  for i in range(1, n+1):\n",
    "    word[i] = sentence[pos+i-1]\n",
    "    word[i] = word[i].upper()\n",
    "  \n",
    "  # read the bigram\n",
    "  selector = (prominence[n].word1==word[1]) & (prominence[n].word2==word[2])\n",
    "  records = prominence[n].loc[selector]\n",
    "  # update the bigram\n",
    "  if len(records.index) == 0:\n",
    "    # insert\n",
    "    c = 1 * param_alpha\n",
    "    signature = {'word1': [word[1]],'word2': [word[2]],'cooc': [c]}\n",
    "    prominence[n] = prominence[n].append(\n",
    "        pd.DataFrame(signature),ignore_index=True, sort=False)\n",
    "  elif len(records.index) == 1:\n",
    "    # update\n",
    "    oldc = records['cooc'].iloc[0]\n",
    "    c = oldc * (1 - param_alpha) + 1 * param_alpha\n",
    "    prominence[n].loc[selector,'cooc'] = c\n",
    "  else:\n",
    "    print(\"Invalid code path\")\n",
    "\n",
    "  # update weights for other bigrams\n",
    "  selector_neg = (prominence[n].word1!=word[1]) & (prominence[n].word2!=word[2])\n",
    "  if param_balancing:\n",
    "    if not selector_neg.empty:\n",
    "      prominence[n].loc[selector_neg,'cooc'] *= (1 - param_alpha)\n",
    "\n",
    "  # finish\n",
    "  if param_verbose:\n",
    "    print(\"Updated bigram: {w1}, {w2}\".format(w1=word[1],w2=word[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ngram3(pos, sentence):\n",
    "  n = 3\n",
    "  word = {}\n",
    "  global prominence\n",
    "  \n",
    "  if pos > len(sentence) - n:\n",
    "    return\n",
    "  for i in range(1, n+1):\n",
    "    word[i] = sentence[pos+i-1]\n",
    "    word[i] = word[i].upper()\n",
    "  \n",
    "  # read the ngram\n",
    "  selector = (prominence[n].word1==word[1]) & (prominence[n].word2==word[2]) & (prominence[n].word3==word[3])\n",
    "  records = prominence[n].loc[selector]\n",
    "  # update the ngram\n",
    "  if len(records.index) == 0:\n",
    "    # insert\n",
    "    c = 1 * param_alpha\n",
    "    signature = {'word1': [word[1]],'word2': [word[2]],'word3': [word[3]],'cooc': [c]}\n",
    "    prominence[n] = prominence[n].append(\n",
    "        pd.DataFrame(signature),ignore_index=True, sort=False)\n",
    "  elif len(records.index) == 1:\n",
    "    # update\n",
    "    oldc = records['cooc'].iloc[0]\n",
    "    c = oldc * (1 - param_alpha) + 1 * param_alpha\n",
    "    prominence[n].loc[selector,'cooc'] = c\n",
    "  else:\n",
    "    print(\"Invalid code path\")\n",
    "\n",
    "  # update weights for other ngrams\n",
    "  selector_neg = (prominence[n].word1!=word[1]) & (prominence[n].word2!=word[2]) & (prominence[n].word3!=word[3])\n",
    "  if param_balancing:\n",
    "    if not selector_neg.empty:\n",
    "      prominence[n].loc[selector_neg,'cooc'] *= (1 - param_alpha)\n",
    "\n",
    "  # finish\n",
    "  if param_verbose:\n",
    "    print(\"Updated bigram: {w1}, {w2}, {w3}\".format(w1=word[1],w2=word[2],w3=word[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ngram4(pos, sentence):\n",
    "  n = 4\n",
    "  word = {}\n",
    "  global prominence\n",
    "  \n",
    "  if pos > len(sentence) - n:\n",
    "    return\n",
    "  for i in range(1, n+1):\n",
    "    word[i] = sentence[pos+i-1]\n",
    "    word[i] = word[i].upper()\n",
    "  \n",
    "  # read the ngram\n",
    "  selector = (prominence[n].word1==word[1]) & (prominence[n].word2==word[2]) & (prominence[n].word3==word[3]) & (prominence[n].word4==word[4])\n",
    "  records = prominence[n].loc[selector]\n",
    "  # update the ngram\n",
    "  if len(records.index) == 0:\n",
    "    # insert\n",
    "    c = 1 * param_alpha\n",
    "    signature = {'word1': [word[1]],'word2': [word[2]],'word3': [word[3]],'word4': [word[4]],'cooc': [c]}\n",
    "    prominence[n] = prominence[n].append(\n",
    "        pd.DataFrame(signature),ignore_index=True, sort=False)\n",
    "  elif len(records.index) == 1:\n",
    "    # update\n",
    "    oldc = records['cooc'].iloc[0]\n",
    "    c = oldc * (1 - param_alpha) + 1 * param_alpha\n",
    "    prominence[n].loc[selector,'cooc'] = c\n",
    "  else:\n",
    "    print(\"Invalid code path\")\n",
    "\n",
    "  # update weights for other ngrams\n",
    "  selector_neg = (prominence[n].word1!=word[1]) & (prominence[n].word2!=word[2]) & (prominence[n].word3!=word[3]) & (prominence[n].word4!=word[4])\n",
    "  if param_balancing:\n",
    "    if not selector_neg.empty:\n",
    "      prominence[n].loc[selector_neg,'cooc'] *= (1 - param_alpha)\n",
    "\n",
    "  # finish\n",
    "  if param_verbose:\n",
    "    print(\"Updated bigram: {w1}, {w2}, {w3}, {4}\".format(w1=word[1],w2=word[2],w3=word[3],w4=word[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus():\n",
    "  with open(param_corpus) as infile:\n",
    "    for line in infile:\n",
    "      for sentence in nltk.sent_tokenize(line):\n",
    "        tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "        for pos, word in enumerate(tokenized_sentence):\n",
    "          process_ngram1(pos, tokenized_sentence)\n",
    "          process_ngram2(pos, tokenized_sentence)\n",
    "          process_ngram3(pos, tokenized_sentence)\n",
    "          process_ngram4(pos, tokenized_sentence)\n",
    "          # print(\"Processing: {w}\".format(w=word))\n",
    "  print(\"Done processing corpus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing corpus\n"
     ]
    }
   ],
   "source": [
    "process_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>word3</th>\n",
       "      <th>word4</th>\n",
       "      <th>cooc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>,</td>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>THE</td>\n",
       "      <td>0.685191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>!</td>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>THE</td>\n",
       "      <td>0.595268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>,</td>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>HE</td>\n",
       "      <td>0.222179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45836</th>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>THE</td>\n",
       "      <td>SHADOW</td>\n",
       "      <td>0.222179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13418</th>\n",
       "      <td>AND</td>\n",
       "      <td>SAID</td>\n",
       "      <td>,</td>\n",
       "      <td>“</td>\n",
       "      <td>0.206386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19199</th>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>THE</td>\n",
       "      <td>LITTLE</td>\n",
       "      <td>0.182093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23213</th>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>THE</td>\n",
       "      <td>OLD</td>\n",
       "      <td>0.173831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>?</td>\n",
       "      <td>”</td>\n",
       "      <td>ASKED</td>\n",
       "      <td>THE</td>\n",
       "      <td>0.165486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17291</th>\n",
       "      <td>,</td>\n",
       "      <td>AND</td>\n",
       "      <td>SAID</td>\n",
       "      <td>,</td>\n",
       "      <td>0.165486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>THE</td>\n",
       "      <td>PRINCESS</td>\n",
       "      <td>0.148542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>?</td>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>THE</td>\n",
       "      <td>0.148542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>,</td>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>SHE</td>\n",
       "      <td>0.139942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45216</th>\n",
       "      <td>THE</td>\n",
       "      <td>LEARNED</td>\n",
       "      <td>MAN</td>\n",
       "      <td>.</td>\n",
       "      <td>0.139942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>SHE</td>\n",
       "      <td>.</td>\n",
       "      <td>0.131254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>HE</td>\n",
       "      <td>,</td>\n",
       "      <td>0.131254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>!</td>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>HE</td>\n",
       "      <td>0.122479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45215</th>\n",
       "      <td>SAID</td>\n",
       "      <td>THE</td>\n",
       "      <td>LEARNED</td>\n",
       "      <td>MAN</td>\n",
       "      <td>0.113615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45214</th>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>THE</td>\n",
       "      <td>LEARNED</td>\n",
       "      <td>0.113615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45837</th>\n",
       "      <td>SAID</td>\n",
       "      <td>THE</td>\n",
       "      <td>SHADOW</td>\n",
       "      <td>.</td>\n",
       "      <td>0.113615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>”</td>\n",
       "      <td>SAID</td>\n",
       "      <td>HE</td>\n",
       "      <td>.</td>\n",
       "      <td>0.113615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word1    word2    word3     word4      cooc\n",
       "332       ,        ”     SAID       THE  0.685191\n",
       "2337      !        ”     SAID       THE  0.595268\n",
       "1009      ,        ”     SAID        HE  0.222179\n",
       "45836     ”     SAID      THE    SHADOW  0.222179\n",
       "13418   AND     SAID        ,         “  0.206386\n",
       "19199     ”     SAID      THE    LITTLE  0.182093\n",
       "23213     ”     SAID      THE       OLD  0.173831\n",
       "917       ?        ”    ASKED       THE  0.165486\n",
       "17291     ,      AND     SAID         ,  0.165486\n",
       "2360      ”     SAID      THE  PRINCESS  0.148542\n",
       "1136      ?        ”     SAID       THE  0.148542\n",
       "3007      ,        ”     SAID       SHE  0.139942\n",
       "45216   THE  LEARNED      MAN         .  0.139942\n",
       "2239      ”     SAID      SHE         .  0.131254\n",
       "1219      ”     SAID       HE         ,  0.131254\n",
       "2427      !        ”     SAID        HE  0.122479\n",
       "45215  SAID      THE  LEARNED       MAN  0.113615\n",
       "45214     ”     SAID      THE   LEARNED  0.113615\n",
       "45837  SAID      THE   SHADOW         .  0.113615\n",
       "2428      ”     SAID       HE         .  0.113615"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prominence[4].sort_values(by='cooc', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persist the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore(param_model)\n",
    "\n",
    "store['prominence_n1'] = prominence[1]\n",
    "store['prominence_n2'] = prominence[2]\n",
    "store['prominence_n3'] = prominence[3]\n",
    "store['prominence_n4'] = prominence[4]\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
